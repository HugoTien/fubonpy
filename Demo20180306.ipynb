{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance\n",
    "- pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting editdistance\n",
      "  Downloading editdistance-0.4-cp36-cp36m-win_amd64.whl\n",
      "Installing collected packages: editdistance\n",
      "Successfully installed editdistance-0.4\n"
     ]
    }
   ],
   "source": [
    "! pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import editdistance\n",
    "editdistance.eval('banana', 'bahama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'banana' # n => h\n",
    "'bahana' # n => m\n",
    "'bahama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import editdistance\n",
    "editdistance.eval('machine', 'macinae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'machine' #=> delete h\n",
    "'macine'  #=> insert a\n",
    "'macinae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = ['How to format my hard disk', 'Hard disk format problems']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(content)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disk', 'format', 'hard', 'how', 'my', 'problems', 'to']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 toy 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "Imaging databases provide storage capabilities.\n",
      "Most imaging databases safe images permanently.\n",
      "Imaging databases store data.\n",
      "Imaging databases store data. Imaging databases store data. Imaging databases store data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'data/toy'\n",
    "for f in os.listdir(path):\n",
    "    print(open(os.path.join(path, f)).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a toy post about machine learning. Actually, it contains not much interesting stuff.',\n",
       " 'Imaging databases provide storage capabilities.',\n",
       " 'Most imaging databases safe images permanently.',\n",
       " 'Imaging databases store data.',\n",
       " 'Imaging databases store data. Imaging databases store data. Imaging databases store data.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = [open(os.path.join(path, f)).read() for f in os.listdir(path)]\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x25 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X= vectorizer.fit_transform(posts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3,\n",
       "        0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'actually', 'capabilities', 'contains', 'data', 'databases', 'images', 'imaging', 'interesting', 'is', 'it', 'learning', 'machine', 'most', 'much', 'not', 'permanently', 'post', 'provide', 'safe', 'storage', 'store', 'stuff', 'this', 'toy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3,\n",
       "        0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x25 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = 'imaging database qoo'\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4494897427831779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "a = np.array([1,1,0,0,1])\n",
    "b = np.array([0,1,1,0,1])\n",
    "\n",
    "# method 1\n",
    "sum((a - b) ** 2) ** (1/2)\n",
    "\n",
    "# method 2\n",
    "#np.array([a,b])\n",
    "sp.linalg.norm(np.array([a,b]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算imaging database 與每篇文章的距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=3.87: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=2.00: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=2.24: Most imaging databases safe images permanently.\n",
      "=== Post 3 with dist=1.73: Imaging databases store data.\n",
      "=== Post 4 with dist=5.57: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 3 with dist=1.73\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_doc = None\n",
    "best_dist = 999\n",
    "best_i = None\n",
    "num_samples = len(posts)\n",
    "for i in range(0, num_samples):\n",
    "    post = posts[i]\n",
    "    if post==new_post:\n",
    "        continue\n",
    "    post_vec = X.getrow(i)\n",
    "    d = dist(post_vec, new_post_vec)\n",
    "    print(\"=== Post %i with dist=%.2f: %s\"%(i, d, post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\"%(best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用sklearn 的 euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.87298335,  2.        ,  2.23606798,  1.73205081,  5.56776436]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "ed = euclidean_distances(new_post_vec, X)\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imaging databases store data.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pos = ed.argsort()[0][0]\n",
    "pos = ed.argsort().flatten()[0]\n",
    "posts[pos]\n",
    "#posts[pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改距離計算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284271247461903"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "a = np.array([1,1,0,0,1])\n",
    "b = np.array([0,1,1,0,1])\n",
    "c = np.array([1,1,0,0,1,0,0,0,0,0,0,0])\n",
    "d = np.array([1,1,0,0,1,1,1,1,1,1])\n",
    "a\n",
    "sp.linalg.norm([d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(v1, v2):\n",
    "    v1_normalized  = v1 / sp.linalg.norm(v1) \n",
    "    v2_normalized  = v2 / sp.linalg.norm(v2)\n",
    "    delta = v1_normalized - v2_normalized\n",
    "    return sp.linalg.norm(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=1.05: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=1.09: Most imaging databases safe images permanently.\n",
      "=== Post 3 with dist=1.00: Imaging databases store data.\n",
      "=== Post 4 with dist=1.00: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 3 with dist=1.00\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_doc = None\n",
    "best_dist = 999\n",
    "best_i = None\n",
    "num_samples = len(posts)\n",
    "for i in range(0, num_samples):\n",
    "    post = posts[i]\n",
    "    if post==new_post:\n",
    "        continue\n",
    "    post_vec = X.getrow(i).toarray()\n",
    "    d = dist(post_vec, new_post_vec.toarray())\n",
    "    print(\"=== Post %i with dist=%.2f: %s\"%(i, d, post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\"%(best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'capabilities',\n",
       " 'contains',\n",
       " 'data',\n",
       " 'databases',\n",
       " 'images',\n",
       " 'imaging',\n",
       " 'interesting',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'permanently',\n",
       " 'post',\n",
       " 'provide',\n",
       " 'safe',\n",
       " 'storage',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'toy']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(posts)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afterwards',\n",
       " 'hundred',\n",
       " 'them',\n",
       " 'more',\n",
       " 'name',\n",
       " 'against',\n",
       " 'beside',\n",
       " 'indeed',\n",
       " 'the',\n",
       " 'about']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.get_stop_words())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 nltk\n",
    "- pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphic'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.stem\n",
    "s = nltk.stem.SnowballStemmer('english')\n",
    "s.stem('graphics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('imaging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imagin'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('imagination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imagin'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('imagine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        # retunr lambda doc : (analyzer(doc))\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = StemmedCountVectorizer(min_df=1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actual', 'capabl', 'contain', 'data', 'databas', 'imag', 'interest', 'learn', 'machin', 'perman', 'post', 'provid', 'safe', 'storag', 'store', 'stuff', 'toy']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = 'imaging database qoo'\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(v1, v2):\n",
    "    v1_normalized  = v1 / sp.linalg.norm(v1) \n",
    "    v2_normalized  = v2 / sp.linalg.norm(v2)\n",
    "    delta = v1_normalized - v2_normalized\n",
    "    return sp.linalg.norm(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=0.86: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.63: Most imaging databases safe images permanently.\n",
      "=== Post 3 with dist=0.77: Imaging databases store data.\n",
      "=== Post 4 with dist=0.77: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 2 with dist=0.63\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_doc = None\n",
    "best_dist = 999\n",
    "best_i = None\n",
    "num_samples = len(posts)\n",
    "for i in range(0, num_samples):\n",
    "    post = posts[i]\n",
    "    if post==new_post:\n",
    "        continue\n",
    "    post_vec = X.getrow(i).toarray()\n",
    "    d = dist(post_vec, new_post_vec.toarray())\n",
    "    print(\"=== Post %i with dist=%.2f: %s\"%(i, d, post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\"%(best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'actually', 'capabilities', 'contains', 'data', 'databases', 'images', 'imaging', 'interesting', 'is', 'it', 'learning', 'machine', 'most', 'much', 'not', 'permanently', 'post', 'provide', 'safe', 'storage', 'store', 'stuff', 'this', 'toy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.26726124,  0.26726124,  0.        ,  0.26726124,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.26726124,  0.26726124,\n",
       "         0.26726124,  0.26726124,  0.26726124,  0.        ,  0.26726124,\n",
       "         0.26726124,  0.        ,  0.26726124,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.26726124,  0.26726124,  0.26726124],\n",
       "       [ 0.        ,  0.        ,  0.52451722,  0.        ,  0.        ,\n",
       "         0.29550385,  0.        ,  0.29550385,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.52451722,  0.        ,\n",
       "         0.52451722,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.26169047,  0.46449871,  0.26169047,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.46449871,  0.        ,\n",
       "         0.        ,  0.46449871,  0.        ,  0.        ,  0.46449871,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.57974759,\n",
       "         0.40483667,  0.        ,  0.40483667,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.57974759,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.57974759,\n",
       "         0.40483667,  0.        ,  0.40483667,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.57974759,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(posts)\n",
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=1,stop_words='english')\n",
    "X = vectorizer.fit_transform(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual',\n",
       " 'capabl',\n",
       " 'contain',\n",
       " 'data',\n",
       " 'databas',\n",
       " 'imag',\n",
       " 'interest',\n",
       " 'learn',\n",
       " 'machin',\n",
       " 'perman',\n",
       " 'post',\n",
       " 'provid',\n",
       " 'safe',\n",
       " 'storag',\n",
       " 'store',\n",
       " 'stuff',\n",
       " 'toy']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = 'imaging database qoo'\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist=1.41: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "=== Post 1 with dist=1.08: Imaging databases provide storage capabilities.\n",
      "=== Post 2 with dist=0.86: Most imaging databases safe images permanently.\n",
      "=== Post 3 with dist=0.92: Imaging databases store data.\n",
      "=== Post 4 with dist=0.92: Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "Best post is 2 with dist=0.86\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_doc = None\n",
    "best_dist = 999\n",
    "best_i = None\n",
    "num_samples = len(posts)\n",
    "for i in range(0, num_samples):\n",
    "    post = posts[i]\n",
    "    if post==new_post:\n",
    "        continue\n",
    "    post_vec = X.getrow(i).toarray()\n",
    "    d = dist(post_vec, new_post_vec.toarray())\n",
    "    print(\"=== Post %i with dist=%.2f: %s\"%(i, d, post))\n",
    "    if d<best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i\n",
    "print(\"Best post is %i with dist=%.2f\"%(best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
